{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Variational QML ( Pennylane )\n",
    "\n",
    "Reference :\n",
    "Xanadu. (n.d.). Post-variational quantum neural networks. PennyLane. Retrieved [date], from https://pennylane.ai/qml/demos/tutorial_post-variational_quantum_neural_networks\n",
    "\n",
    "\n",
    "## Introduction _ why post-variational qml?\n",
    "\n",
    "many ansatz in the variational strategy face **the barren plateau problem**,  which leads to difficulty in convergence using gradient-based optimization techniques. Due to the general difficulty and lack of training guarantees of variational algorithms, here we will develop an alternative training strategy that does not involve tuning the quantum circuit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and datasets from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "from itertools import combinations\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits dataset with features (X_digits) and labels (y_digits)\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "\n",
    "\n",
    "# Create a boolean mask array of the same length as the labels\n",
    "# np.isin returns True or False based on whether the label is in the specified list [2,6]\n",
    "filter_mask = np.isin(y_digits, [2, 6])\n",
    "\n",
    "\n",
    "# Example of the mask to the feature and label arrays\n",
    "# arr = [1,2,3,4,5,6]\n",
    "# mask = [True, False, True, False, True, False]\n",
    "# print(np.array(arr)[mask])\n",
    "\n",
    "\n",
    "# Apply the filter mask to the features and labels to keep only the selected digits\n",
    "# filter_mask is the array that contains True for the indices that are 2 or 6\n",
    "X_digits = X_digits[filter_mask]\n",
    "y_digits = y_digits[filter_mask]\n",
    "\n",
    "\n",
    "# Split the filtered dataset into training and testing sets with 10% of data reserved for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize the pixel values in the training and testing data\n",
    "# Convert each image from a 1D array to an 8x8 2D array, normalize pixel values, and scale them\n",
    "'''\n",
    "Reshape: Each image in X_train and X_test is originally a 1D array. The code reshapes each image into an 8x8 2D array.\n",
    "Normalize: The pixel values are divided by 16 to normalize them. This scales the pixel values to a range of 0 to 1.\n",
    "Scale: The normalized pixel values are then scaled by multiplying by (2 \\pi). \n",
    "This scales the values to a range of 0 to (2 \\pi), which is useful for certain types of neural networks, \n",
    "especially those involving trigonometric functions.\n",
    "'''\n",
    "X_train = np.array([item.reshape([8, 8]) / 16 * 2 * np.pi for item in X_train])\n",
    "X_test = np.array([item.reshape([8, 8]) / 16 * 2 * np.pi for item in X_test])\n",
    "\n",
    "# Adjust the labels to be centered around 0 and scaled to be in the range -1 to 1\n",
    "# The original labels (2 and 6) are mapped to -1 and 1 respectively\n",
    "y_train = (y_train - 4) / 2\n",
    "y_test = (y_test - 4) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, layout=\"constrained\")\n",
    "\n",
    "\n",
    "# Display 6 images in the training set\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "      axes[i][j].matshow(X_train[2*(2*j+i)])\n",
    "      axes[i][j].axis('off')\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define Feature Map and Anasatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feaures : 8 x 8 pixel tensor\n",
    "\n",
    "def feature_map(features):\n",
    "\n",
    "    # apply H gates for superposition\n",
    "    for i in range(len(features[0])):\n",
    "        qml.Hadamard(i)\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "\n",
    "        # apply RZ, RX gates for each pixel\n",
    "        # a\n",
    "        if i % 2 == 1:\n",
    "            qml.AngleEmbedding(features[i], wires=range(len(features[0])), rotation='Z')  # even number of pixel row\n",
    "        \n",
    "        else:\n",
    "            qml.AngleEmbedding(features[i], wires=range(len(features[0])) , rotation='X') # odd number of pixel row\n",
    "        \n",
    "\n",
    "def ansatz(params):\n",
    "\n",
    "    # Ry rotations with the 1st set of param\n",
    "    for i in range(8):\n",
    "        qml.RY(params[i], wires=i)\n",
    "    \n",
    "    # CNOTs cyclically connected ( entanglement )\n",
    "    for i in range(8):\n",
    "        qml.CNOT(wires=[ (i-1)%8, i%8 ])  # (7,0), (0,1), (1,2), ... (6,7)\n",
    "\n",
    "    # RY rotations with the 2nd set of param\n",
    "    for i in range(8):\n",
    "        qml.RY(params[i+8], wires=i)\n",
    "\n",
    "    \n",
    "    # CNOTs cyclically connected ( entanglement + reverse order )\n",
    "    for i in range(8):\n",
    "        qml.CNOT(wires=[(8 - 2 - i) % 8, (8 - i - 1) % 8])  # (6,7), (5,6), (4,5), ... (1,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### choose device ( simulator )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this decorator do?\n",
    "```python\n",
    "@qml.qnode(dev)  \n",
    "def circuit(params, features):\n",
    "    ...\n",
    "```\n",
    "\n",
    "decorator = wrap-up function\n",
    "\n",
    "moves circuit fun  -> to -> qml.qnode(dev) function for converting circuit to QNode\n",
    "\n",
    "<br>\n",
    "\n",
    "__Transforms the Function__: It converts the circuit function into a QNode, which is a special type of function that can be executed on a quantum device.\n",
    "<br>\n",
    "\n",
    "__Manages Quantum Device Execution__: The decorator ensures that the quantum operations defined within the circuit function are executed on the specified quantum device (dev).\n",
    "<br>\n",
    "\n",
    "__Handles Quantum State and Measurements__: It manages the quantum state preparation, execution of quantum gates, and measurement of expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=8) # statevector simulator in pennylane\n",
    "\n",
    "@qml.qnode(dev) # move the quantum circuit to the device\n",
    "def circuit(weights_param, features):\n",
    "\n",
    "    feature_map(features) # encode features to quantum state\n",
    "    ansatz(weights_param) # apply the ansatz with the weights\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)) # measurement of the 1st qubit with PauliZ \n",
    "\n",
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, features=x) + bias   # return the output of the circuit + bias = expval(PauliZ) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    return np.mean( (labels - qml.math.stack(predictions)) ** 2 )\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum([np.sign(l) == np.sign(p) for l, p in zip(labels, predictions)])\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def cost(params, X, Y):\n",
    "    predictions = [variational_classifier(params[\"weights\"], params[\"bias\"], x) for x in X]\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "\n",
    "def acc(params, X, Y):\n",
    "    predictions = [variational_classifier(params[\"weights\"], params[\"bias\"], x) for x in X]\n",
    "    return accuracy(Y, predictions)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Initialize the weights, bias, and parameters\n",
    "weights = 0.01 * np.random.randn(16)\n",
    "bias = jnp.array(0.0)\n",
    "params = {\"weights\": weights, \"bias\": bias}\n",
    "\n",
    "# Initialize the optimizer\n",
    "opt = optax.adam(0.05)\n",
    "\n",
    "# Batch the data\n",
    "batch_size = 7\n",
    "num_batch = X_train.shape[0] // batch_size\n",
    "opt_state = opt.init(params)\n",
    "X_batched = X_train.reshape([-1, batch_size, 8, 8])\n",
    "y_batched = y_train.reshape([-1, batch_size])\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_step_jit(i, args):\n",
    "    params, opt_state, data, targets, batch_no = args\n",
    "    _data = data[batch_no % num_batch]\n",
    "    _targets = targets[batch_no % num_batch]\n",
    "    _, grads = jax.value_and_grad(cost)(params, _data, _targets)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return (params, opt_state, data, targets, batch_no + 1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def optimization_jit(params, data, targets):\n",
    "    opt_state = opt.init(params)\n",
    "    args = (params, opt_state, data, targets, 0)\n",
    "    (params, opt_state, _, _, _) = jax.lax.fori_loop(0, 200, update_step_jit, args)\n",
    "    return params\n",
    "\n",
    "\n",
    "params = optimization_jit(params, X_batched, y_batched)\n",
    "var_train_acc = acc(params, X_train, y_train)\n",
    "var_test_acc = acc(params, X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", var_train_acc)\n",
    "print(\"Testing accuracy: \", var_test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3recon_new",
   "language": "python",
   "name": "l3recon_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
